{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitvenvvenv128625fee99c462192326d997787e3fe",
   "display_name": "Python 3.6.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "I0909 18:13:21.476081 140734783421888 configuration_utils.py:300] Model config BertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 8002\n}\n\nusing cached model\nusing cached model\nusing cached model\n"
    }
   ],
   "source": [
    "from model import make_model\n",
    "import pandas as pd\n",
    "from kobert.utils import get_tokenizer\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "\n",
    "\n",
    "maxlen=25\n",
    "path='./data/ChatBotData.csv'\n",
    "\n",
    "df = pd.read_csv(path, header=0, encoding='utf-8')\n",
    "_, vocab = make_model(1)\n",
    "sp = SentencepieceTokenizer(get_tokenizer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11823"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ids, a_ids = [], []\n",
    "for i in range(len(df)):\n",
    "    question = df.loc[i, 'Q']\n",
    "    answer = df.loc[i, 'A']\n",
    "\n",
    "    q_ids.append([vocab.token_to_idx[tok] for tok in sp(question)])\n",
    "    a_ids.append([vocab.token_to_idx[tok] for tok in sp(answer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_count = [0] * len(vocab)\n",
    "a_count = [0] * len(vocab)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(q_ids[i])): q_count[q_ids[i][j]]+=1\n",
    "    for j in range(len(a_ids[i])): a_count[a_ids[i][j]]+=1\n",
    "\n",
    "q_dict={}\n",
    "a_dict={}\n",
    "qa_dict={}\n",
    "for i in range(len(vocab)):\n",
    "    q_dict[vocab.idx_to_token[i]] = q_count[i]\n",
    "    a_dict[vocab.idx_to_token[i]] = a_count[i]\n",
    "    qa_dict[vocab.idx_to_token[i]] = q_count[i]+a_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dict = {k: v for k, v in sorted(q_dict.items(), key=lambda a: a[1], reverse=True)}\n",
    "a_dict = {k: v for k, v in sorted(a_dict.items(), key=lambda a: a[1], reverse=True)}\n",
    "qa_dict = {k: v for k, v in sorted(qa_dict.items(), key=lambda a: a[1], reverse=True)}"
   ]
  }
 ]
}